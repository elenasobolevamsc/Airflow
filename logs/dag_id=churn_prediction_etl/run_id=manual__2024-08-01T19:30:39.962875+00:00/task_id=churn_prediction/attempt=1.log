[2024-08-01T19:30:42.233+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: churn_prediction_etl.churn_prediction manual__2024-08-01T19:30:39.962875+00:00 [queued]>
[2024-08-01T19:30:42.240+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: churn_prediction_etl.churn_prediction manual__2024-08-01T19:30:39.962875+00:00 [queued]>
[2024-08-01T19:30:42.240+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-08-01T19:30:42.252+0000] {taskinstance.py:2217} INFO - Executing <Task(ClickHouseOperatorExtended): churn_prediction> on 2024-08-01 19:30:39.962875+00:00
[2024-08-01T19:30:42.259+0000] {standard_task_runner.py:60} INFO - Started process 270 to run task
[2024-08-01T19:30:42.263+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'churn_prediction_etl', 'churn_prediction', 'manual__2024-08-01T19:30:39.962875+00:00', '--job-id', '42', '--raw', '--subdir', 'DAGS_FOLDER/churn_prediction_etl.py', '--cfg-path', '/tmp/tmpcgepvy57']
[2024-08-01T19:30:42.265+0000] {standard_task_runner.py:88} INFO - Job 42: Subtask churn_prediction
[2024-08-01T19:30:42.313+0000] {task_command.py:423} INFO - Running <TaskInstance: churn_prediction_etl.churn_prediction manual__2024-08-01T19:30:39.962875+00:00 [running]> on host 16c05e324510
[2024-08-01T19:30:42.387+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Smalch' AIRFLOW_CTX_DAG_ID='churn_prediction_etl' AIRFLOW_CTX_TASK_ID='churn_prediction' AIRFLOW_CTX_EXECUTION_DATE='2024-08-01T19:30:39.962875+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-08-01T19:30:39.962875+00:00'
[2024-08-01T19:30:42.396+0000] {base.py:83} INFO - Using connection ID 'clickhouse' for task execution.
[2024-08-01T19:30:42.396+0000] {clickhouse.py:79} INFO - CREATE TABLE telecom.tab1
ENGINE = MergeTree()
ORDER BY customerID
AS
SELECT customerID
	, BeginDate	
	, EndDate
	, Type
	, PaperlessBilling
	, PaymentMethod
	, MonthlyCharges
	, TotalCharges
	, IF(EndDate = 'No', 0, 1) AS Churn
	, IF(EndDate = 'No', '2020-02-01', EndDate) AS EndDate_new
FROM telecom.contract
[2024-08-01T19:30:42.419+0000] {clickhouse.py:79} INFO - ALTER TABLE telecom.tab1 DROP COLUMN EndDate
[2024-08-01T19:30:42.434+0000] {clickhouse.py:79} INFO - ALTER TABLE telecom.tab1 RENAME COLUMN EndDate_new TO EndDate
[2024-08-01T19:30:42.447+0000] {clickhouse.py:79} INFO - ALTER TABLE telecom.tab1
MODIFY COLUMN EndDate DateTime
[2024-08-01T19:30:42.464+0000] {clickhouse.py:79} INFO - CREATE TABLE telecom.tab2
ENGINE = MergeTree()
ORDER BY customerID
AS
SELECT customerID
	, Type
	, PaperlessBilling
	, PaymentMethod
	, MonthlyCharges
    , toFloat64OrZero(TotalCharges) AS TotalCharges
    , dateDiff('day', BeginDate, EndDate) AS Lifetime
    , Churn
FROM telecom.tab1
[2024-08-01T19:30:42.478+0000] {clickhouse.py:79} INFO - DROP TABLE telecom.tab1
[2024-08-01T19:30:42.480+0000] {clickhouse.py:79} INFO - CREATE TABLE telecom.data
ENGINE = MergeTree()
ORDER BY c.customerID
AS 
SELECT
    c.*,
    p.*,
    if(InternetService = '', 'No', InternetService) AS InternetService,
    if(OnlineSecurity = '', 'No', OnlineSecurity) AS OnlineSecurity,
    if(OnlineBackup = '', 'No', OnlineBackup) AS OnlineBackup,
    if(DeviceProtection = '', 'No', DeviceProtection) AS DeviceProtection,
    if(TechSupport = '', 'No', TechSupport) AS TechSupport,
    if(StreamingTV = '', 'No', StreamingTV) AS StreamingTV,
    if(StreamingMovies = '', 'No', StreamingMovies) AS StreamingMovies,
    if(MultipleLines = '', 'No', MultipleLines) AS MultipleLines

FROM telecom.tab2 AS c
LEFT JOIN telecom.personal AS p ON c.customerID = p.customerID
LEFT JOIN telecom.internet AS i ON c.customerID = i.customerID
LEFT JOIN telecom.phone AS ph ON c.customerID = ph.customerID
[2024-08-01T19:30:42.489+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/opt/airflow/dags/lib/clickhouse_operator_extended.py", line 7, in execute
    return self._hook_execute()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow_clickhouse_plugin/operators/clickhouse.py", line 69, in _hook_execute
    return hook.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow_clickhouse_plugin/hooks/clickhouse.py", line 80, in execute
    last_result = conn.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/clickhouse_driver/client.py", line 382, in execute
    rv = self.process_ordinary_query(
  File "/home/airflow/.local/lib/python3.8/site-packages/clickhouse_driver/client.py", line 580, in process_ordinary_query
    return self.receive_result(with_column_types=with_column_types,
  File "/home/airflow/.local/lib/python3.8/site-packages/clickhouse_driver/client.py", line 213, in receive_result
    return result.get_result()
  File "/home/airflow/.local/lib/python3.8/site-packages/clickhouse_driver/result.py", line 50, in get_result
    for packet in self.packet_generator:
  File "/home/airflow/.local/lib/python3.8/site-packages/clickhouse_driver/client.py", line 229, in packet_generator
    packet = self.receive_packet()
  File "/home/airflow/.local/lib/python3.8/site-packages/clickhouse_driver/client.py", line 246, in receive_packet
    raise packet.exception
clickhouse_driver.errors.ServerException: Code: 57.
DB::Exception: Table telecom.data already exists. Stack trace:

0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x000000000d01e6db
1. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x00000000078dd20c
2. DB::Exception::Exception<String, String>(int, FormatStringHelperImpl<std::type_identity<String>::type, std::type_identity<String>::type>, String&&, String&&) @ 0x00000000078df0ab
3. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000113b9cef
4. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000113af182
5. DB::InterpreterCreateQuery::execute() @ 0x00000000113bdf30
6. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, DB::ReadBuffer*) @ 0x0000000011a7bbe3
7. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x0000000011a77c5a
8. DB::TCPHandler::runImpl() @ 0x0000000012ad714e
9. DB::TCPHandler::run() @ 0x0000000012af2b38
10. Poco::Net::TCPServerConnection::start() @ 0x00000000153ce307
11. Poco::Net::TCPServerDispatcher::run() @ 0x00000000153ce799
12. Poco::PooledThread::run() @ 0x000000001539b4a1
13. Poco::ThreadImpl::runnableEntry(void*) @ 0x0000000015399a5d
14. ? @ 0x00007fe39169ca94
15. ? @ 0x00007fe391729c3c

[2024-08-01T19:30:42.514+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=churn_prediction_etl, task_id=churn_prediction, execution_date=20240801T193039, start_date=20240801T193042, end_date=20240801T193042
[2024-08-01T19:30:42.524+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 42 for task churn_prediction (Code: 57.
DB::Exception: Table telecom.data already exists. Stack trace:

0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x000000000d01e6db
1. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x00000000078dd20c
2. DB::Exception::Exception<String, String>(int, FormatStringHelperImpl<std::type_identity<String>::type, std::type_identity<String>::type>, String&&, String&&) @ 0x00000000078df0ab
3. DB::InterpreterCreateQuery::doCreateTable(DB::ASTCreateQuery&, DB::InterpreterCreateQuery::TableProperties const&, std::unique_ptr<DB::DDLGuard, std::default_delete<DB::DDLGuard>>&, DB::LoadingStrictnessLevel) @ 0x00000000113b9cef
4. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000113af182
5. DB::InterpreterCreateQuery::execute() @ 0x00000000113bdf30
6. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, DB::ReadBuffer*) @ 0x0000000011a7bbe3
7. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x0000000011a77c5a
8. DB::TCPHandler::runImpl() @ 0x0000000012ad714e
9. DB::TCPHandler::run() @ 0x0000000012af2b38
10. Poco::Net::TCPServerConnection::start() @ 0x00000000153ce307
11. Poco::Net::TCPServerDispatcher::run() @ 0x00000000153ce799
12. Poco::PooledThread::run() @ 0x000000001539b4a1
13. Poco::ThreadImpl::runnableEntry(void*) @ 0x0000000015399a5d
14. ? @ 0x00007fe39169ca94
15. ? @ 0x00007fe391729c3c
; 270)
[2024-08-01T19:30:42.554+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-08-01T19:30:42.576+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
